# 02.21.2023
В прошлый раз мы делали все своими силами.
Сегодня будем делать нейронную сеть на основе Keras (входит в Tensorflow).

1. Рассмотрим, как создавать нейронку
2. Обучим 2-3 нейросетки

Решаемые задачи:
1. Нейрон для умножения
2. Нейрон для сложения
3. Нейросеть для классификации изоображений
Задачи 1,2 являются задачами линейной регрессии.

В качестве ДЗ нужно будет самому собрать датасет (хоть kaggle, хоть грабер) и обучить на нём свою нейронку.

# Основные понятия
Рассматривается [следующий проект](https://colab.research.google.com/drive/1LECNnj4y8j_azrfLBbbwGGALncPnkuIy?usp=share_link#scrollTo=ZctkOCawG3hi).
```python
from keras.layers import Dense
from keras.models import Sequential

model = Sequential([
Dense(1, input_shape=(1,), activation='relu')
])

model.summary()
```

-   `Sequential` - это класс последовательности слоев в нейронной сети, у нас пока будет только один слой, но сюда можно добавлять сколь угодно слоев и это будет сеть, состоящая из последовательности слоев.
-   `Dense` - это класс полносвязного/линейного слоя, все нейроны связаны друг с другом.
-   `units=1` - это количество нейронов в слое. У нас 1 нейрон.
-   `input_shape=(1,)` - это входная размерность объекта. У нас только 1 вход.
-   `activation='relu'` - это функция активации, которая добавляет в слой нелинейности, именно из-за неё мы можем получать более сложные результаты работы сети.

```python
model.get_weights()
```
```
[array([[-0.24547338]], dtype=float32), array([0.], dtype=float32)]
```
Веса 2.
Один тот, который мы создали.
+1 смещение Байеса.

Создадим обучающие данные

## Как мы подбираем количество нейронов?
Эмперическим путём.
Гипер-параметр.
Следим за количеством нейронов, смотрим за тем, чтобы нейросеть не переобучилась

## Как мы увидим, что нейросеть переобучилась?
Точность определения данных из выборки обучения стремится к 100%, а точность определения из тестовой выборки падает.

Разом загрузить все данные в нейронную сеть проблематично. Поэтому мы будем загружать данные заданными порциями - batch-ами.

Эпоха - прохождение всего датасета
Итерация - прохождение одного батча

## Можно ли поизгаляться над данными, чтобы увеличить их количество? Повереворачивать изображения, побаловаться с трансофрмацией
Да. Чем больше признаков, тем лучше.

